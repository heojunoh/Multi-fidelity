import GPy
import numpy as np
from matplotlib import pyplot as plt
import matplotlib.mlab as ml
import matplotlib.patches as mpatches
import scipy.stats as stats

import time

l2error= []
meanscore= []
meancrps= []
comptime= []

for kk in range(1, 101): 
 np.random.seed(kk)
 ''' function definitions '''
 def high(x):
  return (x-np.sqrt(2))*low(x)**2
 # return low(x)**2

 def low(x):
  return np.sin(8.0*np.pi*x)

 ''' Define training and test points '''
 dim = 1
 s = 2
 plot = 1
 N1 = 13
 N2 = np.array([8])
 ensemble = 1

 Nts = 1000
 Xtest = np.linspace(0,1, Nts)[:,None]
 Exact= high(Xtest)
 Low = low(Xtest)

 for ii in range(0,N2.shape[0]):
  for jj in range(0,ensemble):

   X1 = np.linspace(0,1, N1)[:,None]
   perm = np.random.permutation(N1)
   X2 = X1[perm[0:N2[ii]]]

   Y1 = low(X1)
   Y2 = high(X2)

   ''' Train level 1 '''
   start = time.time()
   k1 = GPy.kern.RBF(1)
   m1 = GPy.models.GPRegression(X=X1, Y=Y1, kernel=k1)

   m1[".*Gaussian_noise"] = m1.Y.var()*0.01
   m1[".*Gaussian_noise"].fix()

   m1.optimize(max_iters = 500)

   m1[".*Gaussian_noise"].unfix()
   m1[".*Gaussian_noise"].constrain_positive()

   m1.optimize_restarts(20, optimizer = "bfgs",  max_iters = 1000)

   mu1, v1 = m1.predict(X2)


   ''' Train level 2 '''
   XX = np.hstack((X2, mu1))

   k2 = GPy.kern.RBF(1, active_dims = [1])*GPy.kern.RBF(1, active_dims = [0]) \
   + GPy.kern.RBF(1, active_dims = [0])

   m2 = GPy.models.GPRegression(X=XX, Y=Y2, kernel=k2)

   m2[".*Gaussian_noise"] = m2.Y.var()*0.01
   m2[".*Gaussian_noise"].fix()

   m2.optimize(max_iters = 500)

   m2[".*Gaussian_noise"].unfix()
   m2[".*Gaussian_noise"].constrain_positive()

   m2.optimize_restarts(20, optimizer = "bfgs",  max_iters = 1000)


   ''' Predict at test points '''
   # sample f_1 at xtest
   nsamples = 1000
   mu1, C1 = m1.predict(Xtest, full_cov=True)
   Z = np.random.multivariate_normal(mu1.flatten(),C1,nsamples)

   # push samples through f_2
   tmp_m = np.zeros((nsamples,Nts))
   tmp_v = np.zeros((nsamples,Nts))
   for i in range(0,nsamples):
    mu, v = m2.predict(np.hstack((Xtest, Z[i,:][:,None])))
    tmp_m[i,:] = mu.flatten()
    tmp_v[i,:] = v.flatten()

   # get posterior mean and variance
   mean = np.mean(tmp_m, axis = 0)[:,None]
   var = np.mean(tmp_v, axis = 0)[:,None]+ np.var(tmp_m, axis = 0)[:,None]
   var = np.abs(var)
   end = time.time()

   error = np.sqrt(np.mean((mean-Exact)**2))
   score = np.mean(-(Exact-mean)**2/var-np.log(var))
   crps = np.mean(-np.sqrt(var)*(1/np.sqrt(np.pi)-2*stats.norm.pdf((Exact-mean)/np.sqrt(var))-(Exact-mean)/np.sqrt(var)*(2*stats.norm.cdf((Exact-mean)/np.sqrt(var))-1)))
   ctime = (end - start)
   # print( "N1 = %d, N2 = %d, sample = %d, error = %e" % (N1, N2[ii], jj+1, error))

   l2error.append(error)
   meanscore.append(score)
   meancrps.append(crps)
   comptime.append(ctime)

l2error
np.mean(l2error) 
np.sort(l2error) 

meanscore 
np.mean(meanscore) 
np.sort(meanscore) 

meancrps
np.mean(meancrps) 
np.sort(meancrps) 

comptime



### RMSE ### 13, 8
c(0.34022762, 0.34210415, 0.34263473, 0.34509214, 0.34552822,
       0.34640154, 0.34665543, 0.3470831 , 0.34765107, 0.3488693 ,
       0.34954502, 0.3521199 , 0.35284381, 0.35298299, 0.35411262,
       0.35513944, 0.35958212, 0.36015785, 0.36130299, 0.36154642,
       0.36222212, 0.36337812, 0.36387793, 0.36430938, 0.365791  ,
       0.3663411 , 0.36829544, 0.36864227, 0.36901338, 0.36922447,
       0.37038188, 0.37066326, 0.37076633, 0.3707668 , 0.37104885,
       0.37106391, 0.37142202, 0.37205578, 0.37229922, 0.37258915,
       0.37288867, 0.37301391, 0.37356443, 0.37848364, 0.37849521,
       0.37915099, 0.37955322, 0.37983163, 0.38087621, 0.38271045,
       0.38314046, 0.3835409 , 0.38446642, 0.38478077, 0.38487356,
       0.38642814, 0.38651514, 0.38747   , 0.38786221, 0.38793908,
       0.38848576, 0.38956627, 0.39057573, 0.39074492, 0.39074509,
       0.39206265, 0.39780143, 0.40165672, 0.40224004, 0.40319582,
       0.40441013, 0.40627892, 0.40637448, 0.40831034, 0.41006016,
       0.41131778, 0.41437364, 0.41742601, 0.42040924, 0.42262375,
       0.42381744, 0.42381759, 0.42551418, 0.42596411, 0.42739569,
       0.42739967, 0.42842417, 0.42889505, 0.43072772, 0.43418908,
       0.43465899, 0.44231468, 0.44258468, 0.44631899, 0.4543987 ,
       0.45920467, 0.47018402, 0.49496253, 0.50203073, 0.54418115)

### mean CRPS result.nonlinear.meancrps ### The smaller, the better
c(0.19601248, 0.19738676, 0.19935524, 0.19936653, 0.20161979,
       0.20162493, 0.20333192, 0.20357583, 0.20409573, 0.20424958,
       0.20465862, 0.20684365, 0.20722672, 0.20761565, 0.20846041,
       0.20983259, 0.21087637, 0.21155828, 0.21189774, 0.21199481,
       0.21221467, 0.21250487, 0.21254519, 0.2125626 , 0.21264963,
       0.21265009, 0.21268746, 0.21278098, 0.21292538, 0.21302776,
       0.21364283, 0.21425327, 0.21429693, 0.21436857, 0.21456071,
       0.21468787, 0.21531511, 0.21537192, 0.21556793, 0.21610559,
       0.21616138, 0.21639508, 0.21668155, 0.21685781, 0.2176249 ,
       0.21920487, 0.21950093, 0.21967   , 0.21967008, 0.22000444,
       0.2214316 , 0.22251253, 0.22274926, 0.22527235, 0.22570208,
       0.22635634, 0.22637389, 0.22663662, 0.22748233, 0.22788377,
       0.22817972, 0.2281916 , 0.22936076, 0.23056528, 0.23141645,
       0.2327797 , 0.23307097, 0.23513764, 0.2355944 , 0.23648214,
       0.23648222, 0.23787876, 0.23852823, 0.23853046, 0.23913112,
       0.23946125, 0.24158279, 0.2440589 , 0.24746223, 0.2483642 ,
       0.24880676, 0.24899884, 0.25231504, 0.25331067, 0.25364598,
       0.2598985 , 0.2620474 , 0.26451653, 0.27220879, 0.27291315,
       0.27703373, 0.30319667, 0.32853959, 0.33597343, 0.37081451,
       0.38377157, 0.44192297, 0.55535666, 0.65073497, 0.69197052)

### computation time result.nonlinear.comptime ### The smaller, the better
c(12.638431072235107, 14.603119134902954, 9.038669109344482, 12.611816167831421, 8.181637287139893, 
8.41358995437622, 11.093848943710327, 12.64332103729248, 10.260518789291382, 8.836445093154907, 
7.823691129684448, 9.36992883682251, 7.161639928817749, 8.045645236968994, 7.5129311084747314, 
10.962071180343628, 9.90575623512268, 13.129024028778076, 9.923938035964966, 10.478762149810791, 
7.7480552196502686, 5.4767560958862305, 5.874589920043945, 7.085026025772095, 9.507341861724854, 
7.090926647186279, 6.58402419090271, 11.1159029006958, 7.510082721710205, 9.444695949554443, 
11.468750715255737, 7.939141035079956, 9.712474822998047, 7.494318008422852, 6.00114893913269, 
7.759785890579224, 9.164674997329712, 8.371340036392212, 12.275887966156006, 8.428921937942505, 
8.46586298942566, 9.01035213470459, 11.580531120300293, 8.277020931243896, 13.351361751556396, 
11.552864074707031, 10.682437896728516, 10.621850967407227, 7.222555875778198, 9.543353080749512, 
10.435199975967407, 10.084581136703491, 11.306042909622192, 12.817527055740356, 8.33662486076355, 
10.45873498916626, 11.3093900680542, 8.099806070327759, 10.421024084091187, 14.024849891662598, 
8.016197681427002, 11.732913970947266, 11.626074075698853, 12.83341908454895, 12.183241844177246, 
11.139633893966675, 9.099885702133179, 9.223941802978516, 11.819476842880249, 9.258319854736328, 
10.784610986709595, 7.936137914657593, 7.6837029457092285, 7.857706785202026, 11.53866195678711, 
10.071309089660645, 9.193354845046997, 8.42283320426941, 14.498060941696167, 15.400633096694946, 
12.906683921813965, 12.804841995239258, 9.027191638946533, 12.624915838241577, 14.10118818283081, 
8.544509887695312, 10.486035108566284, 13.761353015899658, 9.055784940719604, 11.697642803192139, 
10.145763158798218, 12.498543739318848, 11.528660297393799, 7.321206092834473, 13.920256853103638, 
11.943364143371582, 8.295090913772583, 11.669752836227417, 10.307748317718506, 14.031654119491577)


